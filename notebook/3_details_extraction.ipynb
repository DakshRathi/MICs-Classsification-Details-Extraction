{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional, Tuple\n",
    "from pydantic import BaseModel, Field\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a structured output model for the detailed MIC information\n",
    "class MICDetailedInfo(BaseModel):\n",
    "    \"\"\"Schema for detailed information about a Militarized Interstate Confrontation.\"\"\"\n",
    "    MICdate: date = Field(description=\"The date when the MIC occurred (YYYY-MM-DD format, or as specific as possible)\")\n",
    "    fatality_min: int = Field(description=\"The minimum number of fatalities (use same number as max if precise)\")\n",
    "    fatality_max: int = Field(description=\"The maximum number of fatalities (use same number as min if precise)\")\n",
    "    countries_involved: List[str] = Field(description=\"List of countries involved in the confrontation\")\n",
    "    initiator_country: Optional[str] = Field(description=\"The country that initiated the confrontation, if identifiable\")\n",
    "    target_country: Optional[str] = Field(description=\"The country that was targeted in the confrontation, if identifiable\")\n",
    "\n",
    "def init_llm() -> ChatOpenAI:\n",
    "    \"\"\"Initialize and return the LLM model using LangChain 0.3.\"\"\"\n",
    "    return ChatOpenAI(\n",
    "        base_url=\"http://localhost:1234/v1\",\n",
    "        api_key=\"LMStudio\",\n",
    "        model_name=\"qwen2.5-7b-instruct-1m\",\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "def create_extraction_chain():\n",
    "    \"\"\"Create a LangChain chain for extracting detailed MIC information.\"\"\"\n",
    "    # Initialize components\n",
    "    llm = init_llm()\n",
    "    parser = PydanticOutputParser(pydantic_object=MICDetailedInfo)\n",
    "    format_instructions = parser.get_format_instructions()\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are an expert analyst of international relations and military conflicts.\n",
    "        \n",
    "        This article has been identified as describing a Militarized Interstate Confrontation (MIC).\n",
    "        \n",
    "        Extract the following specific details about this confrontation:\n",
    "        1. The date when the confrontation occurred (be as precise as possible, use YYYY-MM-DD format if date is known else return 0000-00-00) \n",
    "        2. The number of fatalities (provide a range with minimum and maximum values; use the same number for both if precise)\n",
    "        3. All countries involved in the confrontation\n",
    "        4. If possible, identify which country initiated the confrontation and which was the target\n",
    "        \n",
    "        If any information is not explicitly stated in the article, make your best estimate based on context clues.\n",
    "        If you cannot determine a piece of information at all, use null for that field.\n",
    "\n",
    "        Example 1:\n",
    "        Article: \"On March 15, 2022, tensions escalated between Nation A and Nation B, leading to armed skirmishes. Reports confirm at least 50 casualties.\"\n",
    "        \n",
    "        Extracted Details:\n",
    "        ```json\n",
    "        {{\n",
    "            \"MICdate\": \"2022-03-15\",\n",
    "            \"fatality_min\": 50,\n",
    "            \"fatality_max\": 50,\n",
    "            \"countries_involved\": [\"Nation A\", \"Nation B\"],\n",
    "            \"initiator_country\": \"Nation A\",\n",
    "            \"target_country\": \"Nation B\"\n",
    "        }}\n",
    "        ```\n",
    "        \n",
    "        Example 2:\n",
    "        Article: \"In early 1998, a naval conflict arose between Country X and Country Y. The exact number of casualties remains unknown.\"\n",
    "        \n",
    "        Extracted Details:\n",
    "        ```\n",
    "        {{\n",
    "            \"MICdate\": \"1998-01-01\",\n",
    "            \"fatality_min\": 0,\n",
    "            \"fatality_max\": 0,\n",
    "            \"countries_involved\": [\"Country X\", \"Country Y\"],\n",
    "            \"initiator_country\": null,\n",
    "            \"target_country\": null\n",
    "        }}\n",
    "        ```\n",
    "        \n",
    "        Article:\n",
    "        {article}\n",
    "        \n",
    "        {format_instructions}\n",
    "        \"\"\",\n",
    "        input_variables=['article'],\n",
    "        partial_variables={'format_instructions': format_instructions}\n",
    "    )\n",
    "    \n",
    "    # Build the LCEL chain\n",
    "    chain = prompt | llm | parser\n",
    "    \n",
    "    return chain\n",
    "\n",
    "def read_article_file(file_path: Path) -> Optional[str]:\n",
    "    \"\"\"Read an article file with proper error handling for encodings.\"\"\"\n",
    "    try:\n",
    "        # Try UTF-8 first\n",
    "        return file_path.read_text(encoding=\"utf-8\")\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            # Fall back to Latin-1\n",
    "            return file_path.read_text(encoding=\"latin-1\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path.name}: {e}\")\n",
    "            return None\n",
    "\n",
    "def extract_mic_details(chain, article_text: str) -> MICDetailedInfo:\n",
    "    \"\"\"Extract detailed information from the article using the provided chain.\"\"\"\n",
    "    try:\n",
    "        return chain.invoke({\"article\": article_text})\n",
    "    except Exception as e:\n",
    "        # Return a default response if parsing fails\n",
    "        return MICDetailedInfo(MICdate=\"0000-00-00\", fatality_min=0, fatality_max=0, countries_involved=[], initiator_country=None, target_country=None)\n",
    "    \n",
    "def process_mic_articles(base_dir: Path, classified_dir: Path, output_dir: Path, years_to_process: list[str]) -> None:\n",
    "    \"\"\"Process MIC-classified articles to extract detailed information and save using CSV writer\"\"\"\n",
    "    \n",
    "    output_dir.mkdir(parents=True, exist_ok=True)  # Ensure output directory exists\n",
    "    extraction_chain = create_extraction_chain()   # Initialize extraction chain\n",
    "    \n",
    "    # Process each year\n",
    "    for year in years_to_process:\n",
    "        csv_file = classified_dir / f\"{year}_classification.csv\"\n",
    "        output_file = output_dir / f\"{year}_mic_details.csv\"\n",
    "\n",
    "        if not csv_file.exists():\n",
    "            print(f\"Classification file for {year} not found. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Read classified data and filter MIC articles\n",
    "        df = pd.read_csv(csv_file)\n",
    "        mic_articles = df[df['Label'] == 1]\n",
    "        \n",
    "        if mic_articles.empty:\n",
    "            print(f\"No MIC articles found for {year}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Found {len(mic_articles)} MIC articles for {year}.\")\n",
    "\n",
    "        # Load existing processed entries to avoid duplication\n",
    "        existing_entries = set()\n",
    "        if output_file.exists():\n",
    "            with open(output_file, mode=\"r\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                reader = csv.reader(f)\n",
    "                next(reader, None)  # Skip header\n",
    "                for row in reader:\n",
    "                    if row:\n",
    "                        existing_entries.add(row[0])  # Store Index values\n",
    "        \n",
    "        file_mode = \"a\" if output_file.exists() else \"w\"\n",
    "        with open(output_file, mode=file_mode, newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            \n",
    "            # Write headers if it's a new file\n",
    "            if file_mode == \"w\":\n",
    "                writer.writerow([\n",
    "                    'Index', 'MICdate', 'Fatality_Min', 'Fatality_Max', \n",
    "                    'Countries_Involved', 'Initiator_Country', 'Target_Country'\n",
    "                ])\n",
    "\n",
    "            # Process each article\n",
    "            for _, row in tqdm(mic_articles.iterrows(), total=len(mic_articles), desc=f\"Extracting details for {year}\"):\n",
    "                file_index = row['Index']\n",
    "                \n",
    "                # Skip if already processed\n",
    "                if file_index in existing_entries:\n",
    "                    continue\n",
    "                \n",
    "                # Extract article filename and path\n",
    "                article_filename = file_index.split('_', 1)[1]\n",
    "                article_path = base_dir / year / article_filename\n",
    "                \n",
    "                # Read the article content\n",
    "                content = read_article_file(article_path)\n",
    "                if content is None:\n",
    "                    continue\n",
    "                \n",
    "                # Extract details\n",
    "                details = extract_mic_details(extraction_chain, content)\n",
    "                \n",
    "                # Write extracted details to CSV\n",
    "                writer.writerow([\n",
    "                    file_index,\n",
    "                    details.date,\n",
    "                    details.fatality_min,\n",
    "                    details.fatality_max,\n",
    "                    ', '.join(details.countries_involved),\n",
    "                    details.initiator_country,\n",
    "                    details.target_country\n",
    "                ])\n",
    "        \n",
    "        print(f\"Saved detailed information for {len(mic_articles)} MIC articles from {year}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304 MIC articles for year 2008.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba1abbbdc3d47daa85aa07bd047b1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting details for 2008:   0%|          | 0/304 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detailed information for 304 MIC articles from 2008.\n"
     ]
    }
   ],
   "source": [
    "base_dir = Path.cwd().parent / \"processed_files\"\n",
    "classified_dir = Path.cwd().parent / \"classified_files\"\n",
    "detailed_dir = Path.cwd().parent / \"detailed_files\"\n",
    "\n",
    "process_mic_articles(base_dir, classified_dir, detailed_dir, [\"2008\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

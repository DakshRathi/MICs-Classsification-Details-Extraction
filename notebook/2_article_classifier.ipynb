{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from typing import List, Dict, Optional\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel, Field\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output model using Pydantic v2\n",
    "class MICClassificationResult(BaseModel):\n",
    "    \"\"\"Schema for the Militarized Interstate Confrontation classification result.\"\"\"\n",
    "    is_mic: bool = Field(description=\"True if the article describes a Militarized Interstate Confrontation (MIC), False otherwise\")\n",
    "    explanation: str = Field(description=\"A brief explanation of why the article was classified as MIC or not\")\n",
    "\n",
    "def init_llm() -> ChatOpenAI:\n",
    "    \"\"\"Initialize and return the LLM model using LangChain 0.3.\"\"\"\n",
    "    return ChatOpenAI(\n",
    "        base_url=\"http://localhost:1234/v1\",\n",
    "        api_key=\"LMStudio\",\n",
    "        model_name=\"qwen2.5-7b-instruct-1m\",\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "def create_classification_chain():\n",
    "    \"\"\"Create a LangChain classification chain\"\"\"\n",
    "    # Initialize components\n",
    "    llm = init_llm()\n",
    "    parser = PydanticOutputParser(pydantic_object=MICClassificationResult)\n",
    "    format_instructions = parser.get_format_instructions()\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are an expert analyst of international relations and military conflicts.\n",
    "        Your task is to determine whether a news article describes a Militarized Interstate Confrontation (MIC).\n",
    "\n",
    "        A Militarized Interstate Confrontation (MIC) is defined as:\n",
    "        - A direct confrontation between two or more countries\n",
    "        - Involving military forces (army, navy, air force, etc.)\n",
    "        - Where there is a threat, display, or use of military force\n",
    "\n",
    "        The article must describe an actual military interaction, not just diplomatic tensions or discussions about potential conflicts.\n",
    "\n",
    "        Analyze the following article carefully and determine if it describes a MIC.\n",
    "        Output your answer in the specified JSON format with two fields:\n",
    "        1. is_mic: true if it's a MIC, false if it's not\n",
    "        2. explanation: A short explanation of your reasoning\n",
    "\n",
    "        Here are some examples to guide you:\n",
    "        Example 1:\n",
    "        Article: Russian troops opened fire on Ukrainian soldiers near the border, killing three and wounding seven others. The Ukrainian government condemned the attack as a violation of its sovereignty.\n",
    "        Output: {{\"is_mic\": true, \"explanation\": \"This article describes a direct military confrontation between Russian and Ukrainian forces with fatalities, which is a clear case of a Militarized Interstate Confrontation.\"}}\n",
    "\n",
    "        Example 2:\n",
    "        Article: China and Taiwan held diplomatic talks aimed at easing tensions in the region. Both sides agreed to maintain open lines of communication to prevent misunderstandings.\n",
    "        Output: {{\"is_mic\": false, \"explanation\": \"This article describes diplomatic talks rather than a military confrontation. No military forces were involved, and there was no threat or use of force.\"}}\n",
    "\n",
    "        Example 3:\n",
    "        Article: North Korean forces fired artillery shells into South Korean waters as a show of force during joint US-South Korean military exercises. No casualties were reported.\n",
    "        Output: {{\"is_mic\": true, \"explanation\": \"This article describes a militarized action (artillery fire) by North Korea directed at South Korea, which constitutes a Militarized Interstate Confrontation even without casualties.\"}}\n",
    "\n",
    "        Example 4:\n",
    "        Article: The United Nations Security Council met to discuss increasing tensions between India and Pakistan but no military actions were reported.\n",
    "        Output: {{\"is_mic\": false, \"explanation\": \"This article only mentions diplomatic discussions about tensions. It does not describe any actual military confrontation, threat, or use of force between countries.\"}}\n",
    "\n",
    "        Article:\n",
    "        {article}\n",
    "\n",
    "        {format_instructions}\n",
    "        \"\"\",\n",
    "        input_variables=['article'],\n",
    "        partial_variables={'format_instructions': format_instructions}\n",
    "    )\n",
    "    \n",
    "    # Build the LCEL chain\n",
    "    chain = prompt | llm | parser\n",
    "    \n",
    "    return chain\n",
    "\n",
    "def classify_article(chain, article_text: str) -> MICClassificationResult:\n",
    "    \"\"\"Classify an article as MIC or non-MIC using the given chain.\"\"\"\n",
    "    try:\n",
    "        return chain.invoke({\"article\": article_text})\n",
    "    except Exception as e:\n",
    "        # Return a default response if parsing fails\n",
    "        return MICClassificationResult(is_mic=False, explanation=f\"Error in classification: {str(e)}\")\n",
    "\n",
    "def read_article_file(file_path: Path) -> Optional[str]:\n",
    "    \"\"\"Read an article file with proper error handling for encodings.\"\"\"\n",
    "    try:\n",
    "        # Try UTF-8 first\n",
    "        return file_path.read_text(encoding=\"utf-8\")\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            # Fall back to Latin-1\n",
    "            return file_path.read_text(encoding=\"latin-1\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path.name}: {e}\")\n",
    "            return None\n",
    "\n",
    "def process_directory(base_dir: Path, output_dir: Path, years_to_process: list[str]) -> None:\n",
    "    \"\"\"Process all articles in directories and save results to CSV files.\"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Initialize the classification chain\n",
    "    chain = create_classification_chain()\n",
    "    \n",
    "    # Get year folders\n",
    "    year_folders = [f for f in base_dir.iterdir() if f.is_dir() and f.name in years_to_process]\n",
    "    print(f\"Processing {len(year_folders)} specified year folders: {years_to_process}\")\n",
    "    \n",
    "    # Process each year folder with tqdm\n",
    "    for year_folder in tqdm(year_folders, desc=\"Processing years\", position=0):\n",
    "        year_name = year_folder.name\n",
    "        csv_file = output_dir / f\"{year_name}_classification.csv\"\n",
    "        \n",
    "        # Get all article files and sort them by name\n",
    "        article_files = sorted(list(year_folder.glob(\"**/*.txt\")), key=lambda x: x.name)\n",
    "        total_articles = len(article_files)\n",
    "        print(f\"Found {total_articles} articles in {year_name}\")\n",
    "        \n",
    "        # Check if CSV exists and load existing entries to avoid duplicates\n",
    "        existing_entries = set()\n",
    "        if csv_file.exists():\n",
    "            with open(csv_file, mode=\"r\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "                reader = csv.reader(file)\n",
    "                next(reader)  # Skip header\n",
    "                for row in reader:\n",
    "                    if row:  # Skip empty rows\n",
    "                        existing_entries.add(row[0])  # Add index to set\n",
    "            print(f\"Found {len(existing_entries)} existing entries in CSV\")\n",
    "        \n",
    "        # Open CSV in append mode if it exists, or write mode if it doesn't\n",
    "        file_mode = \"a\" if csv_file.exists() else \"w\"\n",
    "        with open(csv_file, mode=file_mode, newline=\"\", encoding=\"utf-8\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write header only if creating a new file\n",
    "            if file_mode == \"w\":\n",
    "                writer.writerow([\"Index\", \"Label\", \"Explanation\"])\n",
    "            \n",
    "            # Process articles with a nested progress bar\n",
    "            with tqdm(total=total_articles, desc=f\"Articles in {year_name}\", position=1, leave=False) as pbar:\n",
    "                \n",
    "                processed = 0\n",
    "                \n",
    "                # Process files in sorted order\n",
    "                for article_file in article_files:\n",
    "                    # Create index for this file\n",
    "                    file_index = f\"{year_name}_{article_file.name}\"\n",
    "                    \n",
    "                    # Skip if already processed\n",
    "                    if file_index in existing_entries:\n",
    "                        pbar.update(1)\n",
    "                        continue\n",
    "                    \n",
    "                    # Read the article\n",
    "                    content = read_article_file(article_file)\n",
    "                    if content is None:\n",
    "                        pbar.update(1)\n",
    "                        continue\n",
    "                    \n",
    "                    # Classify article\n",
    "                    result = classify_article(chain, content)\n",
    "                    writer.writerow([\n",
    "                        file_index,                         # Index\n",
    "                        int(result.is_mic),                 # Label (1 for True, 0 for False)\n",
    "                        result.explanation                  # Explanation\n",
    "                    ])\n",
    "                    \n",
    "                    processed += 1\n",
    "                    \n",
    "                    pbar.update(1)  # Update progress bar after each article\n",
    "        \n",
    "        print(f\"Completed processing for year {year_name}. Added {processed} new entries to {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path.cwd().parent / \"processed_files\"\n",
    "output_dir = Path.cwd().parent / \"classified_files\"\n",
    "\n",
    "print(f\"Starting classification of articles from {base_dir}\")\n",
    "process_directory(base_dir, output_dir, [\"2008\"])\n",
    "print(\"Classification and saving complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
